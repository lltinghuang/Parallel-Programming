# Parallel-Programming

## Introduction
This course covers the fundamentals of parallel computing, focusing on both CPU and GPU optimizations. Through MPI and OpenMP, I learned to implement parallel algorithms such as distributed sorting and fractal computation, understanding different parallel computation models and performance bottlenecks. Moving to CUDA programming, I explored GPU optimizations for graph algorithms and AI-related workloads, improving efficiency with multi-GPU acceleration and memory optimizations.

## Content
- [HW1: Parallel Odd-Even Transposition Sort (MPI)](https://github.com/lltinghuang/Parallel-Programming/tree/main/HW1)
- [HW2: Mandelbort Set (MPI & OpenMP)](https://github.com/lltinghuang/Parallel-Programming/tree/main/HW2)
- [HW3: All-Pair Shortest Path (GPU)](https://github.com/lltinghuang/Parallel-Programming/tree/main/HW3)
- [HW4: FlashAttention Implementation (GPU)](https://github.com/lltinghuang/Parallel-Programming/tree/main/HW4)
- [HW5: Network Benchmark (UCX)](https://github.com/lltinghuang/Parallel-Programming/tree/main/HW5)